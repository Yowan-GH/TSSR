# La gestion du stockage 

- L‚Äôinfrastructure d√©pend de **services** eux-m√™mes d√©pendants des **donn√©es**.
## üß± Concepts fondamentaux

### üìö Les 3 facteurs de l'acc√®s aux donn√©es en environnement virtualis√©

<!-- tabs:start --> 
#### **üîåLa connectique physique**

üìå D√©finition :
> C‚Äôest la **mani√®re mat√©rielle** dont le stockage est **physiquement reli√©** √† l‚Äôh√¥te (ESXi ou autre).

üîπ Exemples :

|Type|Description|
|---|---|
|**SATA / SAS / SSD**|Disques connect√©s directement √† l‚Äôh√¥te (stockage local)|
|**USB / NVMe**|Connexions ponctuelles ou haute performance (local)|
|**Ethernet (RJ45)**|Connexion r√©seau pour NAS / iSCSI (mutualis√©)|
|**Fibre Channel (SFP, LC)**|Connexion fibre optique haut d√©bit (SAN, datacenter)|

#### **üåêLe protocole utilis√©**

üìå D√©finition :
> C‚Äôest la **langue de communication** entre l‚Äôh√¥te et le stockage pour √©changer les donn√©es.
> Il est le lien entre l'OS et le p√©riph√©rique de stockage - D√©pendant de la couche de liaison.

üîπ Quelques protocoles 

<!-- tabs:start --> 

##### **üß± Protocoles de type bloc**

> Les donn√©es sont vues comme des **blocs bruts** (comme un disque local).  
> N√©cessitent un formatage par l‚Äôh√¥te (ex : VMFS, NTFS‚Ä¶).

<!-- tabs:start --> 

###### **SCSI**

- Small Computer System Interface
- **Type** : Bloc
- **Connexion** : Interne ou externe (historiquement en c√¢ble parall√®le)
- **Sp√©cificit√©** : Ajout d'un contr√¥leur SCSI (Carte qui pilote les √©changes entre l‚Äôh√¥te et les p√©riph√©riques SCSI) afin de fluidifier les √©changes entre l'OS et le stockage dans la couche transport du mod√®le OSI (sous forme de commande, dans un canal sp√©cifique). 
- **Utilisation** : Disques durs internes, serveurs anciens
- **Fonctionnement** : 
```java
Application (OS invit√©)
   ‚Üì
Syst√®me de fichiers (ex : NTFS / VMFS)
   ‚Üì
Contr√¥leur SCSI (virtuel ou physique)
   ‚Üì
Bus SCSI (local)
   ‚Üì
Disque dur / p√©riph√©rique de stockage
```

>- Le syst√®me d‚Äôexploitation envoie des **commandes SCSI** au contr√¥leur.
>- Les donn√©es sont transf√©r√©es en **mode bloc**, directement via un **bus local** (physique ou virtuel).
>- **Le stockage est directement connect√©** √† l‚Äôh√¥te (local ou via carte SAS/Fibre Channel).
>- Utilis√© pour le **stockage interne ou en SAN via Fibre Channel**.

###### **iSCSI**

- Internet SCSI
- **Type** : Bloc
- **Connexion** : **Via r√©seau IP (Ethernet)**
- - **Avantages** :
    - Facile √† d√©ployer (r√©seau classique)
    - Tr√®s utilis√© dans les environnements vSphere pour **datastores partag√©s**
        
- **Composants** :
    - **Initiator** : le client (ESXi)
    - **Target** : le serveur (baie SAN)
- **Fonctionnement :**
```java
Application (VM / OS invit√©)
   ‚Üì
Syst√®me de fichiers
   ‚Üì
Initiateur iSCSI (logiciel ou mat√©riel)
   ‚Üì
R√©seau IP (Ethernet)
   ‚Üì
Cible iSCSI (baie SAN, NAS iSCSI)
   ‚Üì
Stockage distant (LUN)
```
    
>- Le protocole **iSCSI encapsule les commandes SCSI dans du TCP/IP**.
>- Le **r√©seau Ethernet** (RJ45) remplace le bus SCSI ‚ûî c‚Äôest donc un **SAN sur IP**.
>- Le disque appara√Æt comme **local pour l‚Äôh√¥te**, mais est en fait h√©berg√© **√† distance**.
>- iSCSI est tr√®s utilis√© dans les environnements **vSphere, Hyper-V ou Proxmox** pour **mutualiser le stockage**.

üí°Il est conseill√©, lors de l'utilisation de ce protocole;, d'augmenter la valeur MTU √† 9000.

###### **SAS**

-  Serial Attached SCSI
- **Type** : Bloc
- **Connexion** : Interne (ou externe via bo√Ætier SAS)
- **Utilisation** : Stockage **local professionnel** ou **baie directe**
- **Avantages** : Rapide, fiable, prise en charge du multipathing
- **Fr√©quence** : Tr√®s courant dans les serveurs physiques


###### **Fibre Channel**

- **Type** : Bloc
- **Connexion** : Via fibre optique (connectique SFP+ ou LC)
- **Utilisation** : SAN **haut de gamme** dans les datacenters
- **Avantages** : Tr√®s faible latence, bande passante √©lev√©e (8‚Äì32 Gb/s)
- **Limites** : N√©cessite un r√©seau d√©di√© + √©quipement co√ªteux (HBA, switch FC)

###### **FCoE**

-  Fibre Channel over Ethernet
- **Type** : Bloc
- **Connexion** : Via Ethernet (10 Gb/s mini)
- **Utilisation** : Alternative √† FC, mais sur r√©seau converg√©
- **Avantages** :
    - Moins de c√¢bles
    - Mutualisation du r√©seau
    
- **Limites** : Plus complexe √† configurer, moins utilis√© aujourd‚Äôhui
<!-- tabs:end --> 

##### **üìÅ Protocoles de type fichier**

<!-- tabs:start --> 
###### **NFS**
- Network File System
- **Type** : Fichier
- **Connexion** : IP (TCP/UDP)
- **Utilisation** : **NAS** pour datastores partag√©s dans vSphere
- **Avantages** :
    - Simplicit√© de configuration
    - Acc√®s multi-h√¥tes facile
    
- **Limites** :
    - Moins performant que les protocoles bloc
    - Moins de granularit√© de gestion

###### **CIFS / SMB**
- Common Internet File System / Server Message Block
- **Type** : Fichier
- **Connexion** : IP
- **Utilisation** : Partages de fichiers Windows (stockage secondaire, ISO, backups‚Ä¶)
- **Remarques** :
    - Peu utilis√© pour **les datastores principaux**
    - Pas pris en charge comme datastore VMFS sous vSphere
<!-- tabs:end -->
<!-- tabs:end --> 

##### üß† Comparatif express

| Protocole         | Type    | Usage typique          | Support VMware ESXi                 |
| ----------------- | ------- | ---------------------- | ----------------------------------- |
| **SAS**           | Bloc    | Stockage local         | ‚úÖ                                   |
| **SCSI**          | Bloc    | Stockage ancien/local  | ‚úÖ                                   |
| **iSCSI**         | Bloc    | SAN IP                 | ‚úÖ                                   |
| **Fibre Channel** | Bloc    | SAN optique            | ‚úÖ                                   |
| **FCoE**          | Bloc    | SAN converg√©           | ‚úÖ                                   |
| **NFS**           | Fichier | NAS / stockage partag√© | ‚úÖ                                   |
| **CIFS/SMB**      | Fichier | Partage de fichiers    | ‚ö†Ô∏è limit√© (pas datastore principal) |
#### **üì¶Le mode d'acc√®s**

üìå D√©finition :
> C‚Äôest la mani√®re dont les donn√©es sont **pr√©sent√©es √† l‚Äôhyperviseur** ou au syst√®me d‚Äôexploitation.

<!-- tabs:start --> 
##### **Bloc**
Le stockage bloc divise les donn√©es en blocs de taille fixe et les stocke s√©par√©ment avec un identifiant unique. Le syst√®me d'exploitation g√®re ensuite l'organisation de ces blocs.
En **stockage bloc**, le serveur (ou le PC) peut acc√©der √† **plusieurs blocs en parall√®le**

> Offre **de hautes performances** et une **grande flexibilit√©**.  
> Utilis√© souvent avec des bases de donn√©es ou des machines virtuelles.  

##### **Fichiers**
Le stockage fichier conserve les donn√©es sous forme de fichiers organis√©s dans une arborescence (dossiers/sous-dossiers), accessibles via un protocole r√©seau.

> Plus simple √† utiliser, car structur√© comme un dossier sur un ordinateur.  
> Id√©al pour le partage de documents ou de m√©dias entre utilisateurs.

<!-- tabs:end --> 
<!-- tabs:end --> 
### üì¶ Les 3 types de stockage (en virtualisation)

<!-- tabs:start --> 
#### **Local (h√¥te)**

üìå D√©finition :
Le stockage est directement connect√© **au serveur physique (h√¥te ESXi)**, via des disques internes (SATA, SSD, NVMe...).

üîπCaract√©ristiques :
- Accessible **uniquement par l‚Äôh√¥te local**.
- **Aucune mutualisation
- possible** entre plusieurs serveurs.
- Performant mais **non partag√©**.
- Acc√®s en mode bloc.

‚úÖ Avantages :
- Simple √† mettre en place
- Co√ªt faible
- Bonne performance locale

‚ùå Inconv√©nients :
- Pas de redondance ni de migration possible (pas de vMotion)
- Pas adapt√© √† la haute disponibilit√©

#### **Mutualis√© (r√©seau partag√©)**

 üìå D√©finition :
Le stockage est **partag√© entre plusieurs h√¥tes** via le r√©seau (NAS ou SAN).

üîπ Caract√©ristiques :
- Chaque h√¥te acc√®de au **m√™me espace de stockage** (datastore).
- Utilis√© pour **les fonctions avanc√©es** comme **HA**, **vMotion**, **DRS**.

‚úÖ Avantages :
- Mutualisation des ressources
- Migration de VMs possible entre h√¥tes
- Compatible avec les fonctionnalit√©s avanc√©es de vSphere

‚ùå Inconv√©nients :
- Plus complexe √† configurer
- Co√ªt sup√©rieur
- D√©pend du r√©seau

<!-- tabs:start --> 
##### **üíΩ SAN**

- SAN (Storage Area Network)
- **D√©finition** : R√©seau d√©di√© au stockage qui fournit des disques virtuels aux serveurs. 
	- **‚úÖ SAN = Disques partag√©s + Serveur externe pour la gestion**
- **Type d'acc√®s** : Bas√© sur les **blocs** (block-level).
- **Protocole** : **iSCSI**, **Fibre Channel**, **FCoE**.
- **Avantages** :
    - Tr√®s haute performance.
    - Faible latence, id√©al pour serveurs critiques.
    - Bonne scalabilit√©.
        
- **Inconv√©nients** :
    - Co√ªteux.
    - Complexe √† d√©ployer et maintenir.
        
- **Exemple d'utilisation** : Stockage pour bases de donn√©es, environnements virtualis√©s (VMware, Hyper-V).

##### **üì¶ NAS**

- NAS (Network Attached Storage)
- **D√©finition** : Syst√®me de stockage connect√© au r√©seau permettant de partager des fichiers. 
	- ‚úÖ **NAS = Serveur + Disque + Gestion int√©gr√©e**
- **Type d'acc√®s** : Bas√© sur les **fichiers** (file-level).
- **Protocole** : **SMB/CIFS**, **NFS**, **AFP**.
- **Avantages** :
    - Facile √† installer et g√©rer.
    - Co√ªt faible.
    - Accessible via r√©seau local.
        
- **Inconv√©nients** :
    - Moins performant.
    - D√©pendant du trafic r√©seau.
        
- **Exemple d'utilisation** : Sauvegarde de fichiers, partage de documents dans une PME.

<!-- tabs:end --> 
#### **Centralis√© (SAN/NAS)**

üìå D√©finition :
Le stockage est **enti√®rement dissoci√© des h√¥tes** et centralis√© dans un syst√®me unique (baie SAN/NAS ou cluster de stockage).

üîπ Caract√©ristiques :
- Acc√®s via r√©seau √† un syst√®me **d√©di√©** et **r√©pliqu√©**.
- Hautement disponible, souvent avec **sauvegarde, redondance**, **RAID**, etc.
- Typiquement utilis√© dans les **datacenters**.

‚úÖ Avantages :
- Tr√®s haute fiabilit√©
- Centralisation de l'administration
- R√©plication possible entre sites (DR, PRA)

‚ùå Inconv√©nients :
- Co√ªt √©lev√©
- D√©ploiement technique complexe
<!-- tabs:end --> 

## üì¶ vSphere et le stockage..

Dans une infrastructure **VMware vSphere**, le stockage repose sur deux √©l√©ments cl√©s :

|√âl√©ment|R√¥le|
|---|---|
|**Adaptateurs de stockage**|Permettent √† l‚Äôh√¥te ESXi de **se connecter** √† des supports de stockage locaux ou distants.|
|**Banques de donn√©es (datastores)**|Espace de stockage **logique et structur√©** dans lequel les **VMs sont h√©berg√©es** (disques VMDK, ISO, snapshots‚Ä¶).|

---
### üì¶Choix d‚Äôune solution de stockage

Ce choix d√©pend de plusieurs crit√®res : 

| Crit√®re                 | Question √† se poser                                                |
| ----------------------- | ------------------------------------------------------------------ |
| **D√©di√© ou mutualis√©**  | Le stockage est-il li√© √† un seul h√¥te ou partag√© entre plusieurs ? |
| **Protocole d‚Äôacc√®s**   | Quel protocole sera utilis√© ? (iSCSI, NFS, FC‚Ä¶)                    |
| **Support physique**    | Disque local, NAS, SAN, baie‚Ä¶                                      |
| **Mode d‚Äôacc√®s**        | Bloc ou fichier ?                                                  |
| **Syst√®me de fichiers** | VMFS, NFS, ou autre ?                                              |

<img src="Virtualisation/images/Solution_stockage.png" width="600">


### üì¶Solution de stockage iSCSI
  

<img src="Virtualisation/images/iSCSI.png" width="600">

Cette illustration montre **comment un h√¥te ESXi acc√®de √† un espace de stockage distant**, via le protocole **iSCSI**, √† travers un **r√©seau IP**. Elle contient : 
<!-- tabs:start -->
#### **üß±SAN ‚Äì Storage Area Network**

- Un **r√©seau sp√©cialis√© d√©di√© au stockage**.
- Dans ce cas, c‚Äôest un **SAN iSCSI**, donc utilisant **IP + iSCSI** pour transporter des commandes SCSI.
- Il permet √† plusieurs h√¥tes d‚Äôacc√©der √† un ou plusieurs **espaces disques centralis√©s**, sans passer par un partage de fichiers (comme NFS).
#### **üì¶LUN ‚Äì Logical Unit Number**

- Un **volume logique** d‚Äôune baie de disques.
- Il s‚Äôagit d‚Äôun **disque ou d‚Äôun espace disque virtuel**, expos√© par la baie (ou cible iSCSI) √† l‚Äôh√¥te.
- Chaque LUN (ex : LUN0, LUN1) est vu par ESXi comme un **disque brut**, que l‚Äôon peut formater en VMFS.
#### **üîåHBA ‚Äì Host Bus Adapter**

- C‚Äôest l‚Äô**adaptateur de stockage** du c√¥t√© ESXi.
- Il existe deux types :
    - **HBA physique** : carte r√©seau ou fibre install√©e dans l‚ÄôESXi.
    - **HBA logiciel** : √©mul√© dans ESXi, permet de faire de l‚ÄôiSCSI **sans carte d√©di√©e**.
- Le HBA permet de **communiquer avec la cible iSCSI**.
#### **üéØiSCSI Target**

- C‚Äôest le **serveur de stockage**, ou l‚Äô√©l√©ment qui fournit le disque distant.
- Il expose un ou plusieurs **LUNs** via le protocole iSCSI.
- Il peut √™tre :
    - Une **baie SAN**
    - Un **NAS iSCSI**
    - Un **serveur avec un service iSCSI activ√©**
#### **üöÄiSCSI Initiator**

- C‚Äôest le **client iSCSI**, ici le **serveur ESXi**.
- Il initie une connexion vers la cible iSCSI pour acc√©der aux disques (LUNs).
- L‚Äôinitiator s‚Äôappuie sur un HBA (logiciel ou physique) pour √©tablir la communication.
<!-- tabs:end -->

#### üîÅ **R√©sum√©**

1. ESXi utilise un **HBA (logiciel ou physique)**
2. L‚Äô**Initiator iSCSI** envoie une requ√™te au **Target iSCSI**
3. Le **r√©seau IP** transporte les commandes iSCSI (encapsul√©es en TCP/IP)
4. Le **Target** fournit l‚Äôacc√®s aux **LUNs**
5. L‚ÄôESXi voit les LUNs comme **disques** (stockage bloc)
6. Ils sont ensuite format√©s (ex : en VMFS) pour accueillir des machines virtuelles

### üíæ Les Datastores

#### üß± Qu‚Äôest-ce qu‚Äôun **datastore** ?

> Un **datastore** est une **unit√© logique de stockage** dans vSphere.  
> Il repr√©sente un **espace disque format√©** (locale ou distant) que l‚Äôhyperviseur **ESXi** peut utiliser pour :

- stocker des **fichiers de VMs** (VMDK, VMX, logs‚Ä¶),
- monter des **images ISO**,
- h√©berger des **snapshots** ou **templates**.

#### üìÇ Types de datastores

| Type                           | Description                                                                                                  | Mode d‚Äôacc√®s      |
| ------------------------------ | ------------------------------------------------------------------------------------------------------------ | ----------------- |
| **VMFS** (vSphere File System) | Syst√®me de fichiers propri√©taire VMware utilis√© sur les volumes en mode bloc (disques locaux, SAN iSCSI, FC) | **Bloc**          |
| **NFS** (v3 / v4.1)            | Montage d‚Äôun partage r√©seau (NAS) sur ESXi, en mode fichier                                                  | **Fichier**       |
| **RDM** (Raw Device Mapping)   | LUN mapp√© directement √† une VM, avec le VMFS                                                                 | **Bloc (direct)** |

#### üì¶ VMFS ‚Äì d√©tails

| Version    | Max volume | Format | Particularit√©s                                      |
| ---------- | ---------- | ------ | --------------------------------------------------- |
| **VMFS 3** | 64 To      | MBR    | Obsol√®te                                            |
| **VMFS 5** | 64 To      | GPT    | Alignement automatique, recommand√© depuis vSphere 5 |
| **VMFS 6** | 64 To      | GPT    | Auto-defrag, support du 512e, gestion temps r√©el    |

‚úÖ Le **formatage VMFS est requis sur les disques en mode bloc**.

### üßä Les disques de VM

<!-- tabs:start --> 
#### **üì¶Le format VMDK**

> Un disque de machine virtuelle dans vSphere est stock√© dans un fichier au format **.vmdk**  
> (**Virtual Machine Disk Format**)

Fonctionnement : 
- Le disque est repr√©sent√© par un fichier unique avec pour possibilit√© de le d√©placer, copier ...

Limite : 
- Taille maximale de 2TO, au dela, il faudra utiliser le format RDM

**üß± Types de provisionnement (provisioning) du VMDK**

| Mode     | Description                                                      | Avantages               | Inconv√©nients                |
| -------- | ---------------------------------------------------------------- | ----------------------- | ---------------------------- |
| **Thick  | L‚Äôespace est allou√© et **z√©ro rempli** d√®s la cr√©ation           | Meilleures performances | Long √† cr√©er, espace r√©serv√© |
| **Thin** | L‚Äôespace est allou√© **√† la demande**, selon la croissance r√©elle | Gain de place           | Risque de **sur-allocation** |

#### **üì¶ Le format RDM (Raw Device Mapping)**

Fonctionnement : 
-  Acc√®s direct d‚Äôune VM √† un **LUN SAN**, sans passer par un VMDK.

Utilit√© : 
- Acc√®s √† un disque SAN sp√©cifique : Clustering Windows, r√©plication applicative
- Contournement du syst√®me de fichiers ESXi : Stockage de tr√®s hautes performances, grande capacit√© de stockage (>2TO)

<!-- tabs:end --> 

### üõ†Ô∏è En Pratique

Pour cette d√©monstration, les machines suivantes seront utilis√©es : 
- ESXi
- WS2019 avec fonction iSCSI

1. S'assurer que les machines sont sur le m√™me r√©seau
2. Cr√©er un vSwitch (VSS) sur l'ESXi
3. Cr√©er un GP VMKernel reli√© √† ce vSwitch et lui attribuer une adresse IP (dans le r√©seau r√©serv√© √† l'√©change de bloc de donn√©s) - @IP1
4. Tester depuis le WS2019 l'acc√®s √† @IP1
5. Il faut ensuite Cr√©er les Target iSCSI sur le WS. Elles vont permettre aux hyperviseur de venir chercher les p√©riph√©riques sur ce serveur
	1. ``File and storage Services``
	2. ``iSCSI``
	3. ``Install Target iSCSI``
		1. S√©lectionner la fonctionnalit√© ``iSCSI target server ``
	4. ``Create iSCSI virtual disk``
		1. D√©finir l'emplacement 
		2. Le nommer
		3. Indiquer la taille et la laisser Dynamique 
		4. New target iSCSI
		5. Indiquer l'IP de l'ESXi
		6. Possibilit√© de rajouter une authentification si n√©c√©ssaire
		7. ``Create ``
		8. La target est disponible
6. Retourner sur les ESXi dans ``stockage`` / ``Adaptateur`` / ``iSCSI logiciel`` /`` Activer``
	1. Ajouter une liaison de port - Ajouter le GP correspondant
	2. Ajouter la cible dynamique - @IP du WS
7. ``Actualiser`` puis aller contr√¥ler la d√©couverte du disque dure dans ``P√©riph√©riques``
‚ùóNe pas tenir compte de l'√©tat d√©grad√© de ce disque.

8. Pour exploiter ce nouveau disque, nous allons ``cr√©er une nouvelle banque de donn√©e``
	‚úÖLe faite de cr√©er cette banque de donn√©e reli√©e √† un ESXi cr√©era cette banque sur tous les ESXi sur le m√™me r√©seau (et autoris√© √† y acceder)

9. Je peux ensuite d√©placer ma VM de l'ESXi vers le SAN. Pour cela : 
	1. Eteindre la VM
	2. Aller dans le Datastore hebergeant la VM
	3. Cliquer sur D√©placer
	4. S√©lectionner le nouveau DATAstore
10. La VM n'est donc plus d√©pendante de l'ESXi mais bien du SAN WS
